{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Image Segmentation with FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of kitti road \n",
    "* GT image, background is red, while road is purple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import helper_gxdai as helper\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained VGG-16\n",
    "def load_vgg(sess, vgg_path):\n",
    "    # Loader functionality for SavedModel with hermetic, language-neutral exports.\n",
    "    model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)\n",
    "    \n",
    "    # Get tensor to be returned from graph\n",
    "    \n",
    "    # Return the default graph for the current thread.\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    # Returns the tensor for the given name.\n",
    "    image_input = graph.get_tensor_by_name('image_input:0')\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    layer3 = graph.get_tensor_by_name(\"layer3_out:0\")\n",
    "    layer4 = graph.get_tensor_by_name(\"layer4_out:0\")\n",
    "    layer7 = graph.get_tensor_by_name(\"layer7_out:0\")\n",
    "    \n",
    "    return image_input, keep_prob, layer3, layer4, layer7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the layers for a FCN, using the tensors from the VGG model.\n",
    "* **add 1x1 convolution to encoder.**\n",
    "* **add decoder.**\n",
    "* **add skip connection and upsampling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \n",
    "    # shorter name for simplicity\n",
    "    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "    \n",
    "    # apply 1x1 conv\n",
    "    \n",
    "    # not too much meanings for filters=num_classes.\n",
    "    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name='fcn8')\n",
    "    \n",
    "    # upsampling 2x\n",
    "    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n",
    "                                      kernel_size=4, strides=(2,2), padding='SAME', name='fcn9')\n",
    "    \n",
    "    # skip connection (add)\n",
    "    fcn9_skip_connected = tf.add(layer4, fcn9, name='fcn9_plus_vgg_layer4')\n",
    "    \n",
    "    # upsample again\n",
    "    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n",
    "                                       kernel_size=4, strides=(2,2), padding='SAME', name='fcn10')\n",
    "    # skip connection\n",
    "    fcn10_skip_connected = tf.add(layer3, fcn10, name='fcn10_plus_vgg_layer3')\n",
    "    \n",
    "    # upsample again\n",
    "    \n",
    "    # filters=num_classes for pixel-wise prediction.\n",
    "    \n",
    "    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n",
    "                                       kernel_size=16, strides=(8,8), padding='SAME', name='fcn11')\n",
    "    \n",
    "    # No smooth operation (3x3 conv) in this structure.\n",
    "    \n",
    "    return fcn11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aka: Also Known As"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \n",
    "    # reshape 4D tensor to 2D\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes), name='fcn_logits')\n",
    "    correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes), name='fcn_prediction')\n",
    "    \n",
    "    # taken mean or total loss\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n",
    "    # train op\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op, name='fcn_train_op')\n",
    "    \n",
    "    return logits, train_op, loss_op\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up learning rate, epochs, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n",
    "             cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \n",
    "    keep_prob_value = 0.5\n",
    "    learning_rate_value = 0.001\n",
    "    for epoch in range(epochs):\n",
    "        # create function to get batch.\n",
    "        total_loss = 0\n",
    "        \n",
    "        # get_batches_fn(batch_size): will return a generator.\n",
    "        \n",
    "        for x_batch, gt_batch in get_batches_fn(batch_size):\n",
    "            loss, _ = sess.run([cross_entropy_loss, train_op], feed_dict={\n",
    "                               input_image: x_batch, correct_label: gt_batch,\n",
    "                               keep_prob: keep_prob_value,\n",
    "                               learning_rate: learning_rate_value})\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "        print(\"Epoch {} ...\".format(epoch+1))\n",
    "        print(\"Loss = {:.3f}\".format(total_loss))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(**params_dict):\n",
    "    data_dir = params_dict['data_dir']\n",
    "    training_dir = params_dict['training_dir']\n",
    "    image_shape = params_dict['image_shape']\n",
    "    vgg_path = params_dict['vgg_path']\n",
    "    num_classes = params_dict['num_classes']\n",
    "    correct_label = params_dict['correct_label']\n",
    "    learning_rate = params_dict['learning_rate']\n",
    "    EPOCHS = params_dict['EPOCHS']\n",
    "    BATCH_SIZE = params_dict['BATCH_SIZE']\n",
    "    runs_dir = params_dict['runs_dir']\n",
    "    \n",
    "    # Download pretrained model\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "    \n",
    "    # A function to get batch\n",
    "    get_batches_fn = helper.gen_batch_function(training_dir, image_shape)\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        \n",
    "        # return different args from vgg model.\n",
    "        image_input, keep_prob, layer3, layer4, layer7 = load_vgg(sess, vgg_path)\n",
    "        \n",
    "        # Add decoder on top of the encoder network\n",
    "        model_output = layers(layer3, layer4, layer7, num_classes)\n",
    "        \n",
    "        # returns the output logits, training operations, and cost function.\n",
    "        logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, \n",
    "                                                        learning_rate, num_classes)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        print(\"Model build successfully, start training.\")\n",
    "        \n",
    "        train_nn(sess, EPOCHS, BATCH_SIZE, get_batches_fn,\n",
    "                 train_op, cross_entropy_loss, image_input,\n",
    "                 correct_label, keep_prob, learning_rate)\n",
    "        \n",
    "        helper.save_inference_samples(runs_dir, data_dir, sess, \n",
    "                                      image_shape, logits, \n",
    "                                      keep_prob, image_input)\n",
    "        \n",
    "        print(\"DONE\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the specified model\n",
    "\n",
    "def main():\n",
    "    # parameter settings\n",
    "    num_classes = 2\n",
    "    image_shape = (160, 576)\n",
    "    EPOCHS = 100\n",
    "    BATCH_SIZE = 16\n",
    "    import os\n",
    "    os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "    data_dir = './data'\n",
    "    runs_dir = './runs'\n",
    "    training_dir = './data/data_road/training'\n",
    "    vgg_path = './data/vgg'\n",
    "    \n",
    "    correct_label = tf.placeholder(tf.float32, [None, image_shape[0], image_shape[1], num_classes])\n",
    "    learning_rate = tf.placeholder(tf.float32)\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    params_dict = {\"data_dir\": data_dir, \n",
    "                   \"training_dir\":training_dir, \n",
    "                   \"image_shape\": image_shape, \n",
    "                   \"vgg_path\": vgg_path, \n",
    "                   \"num_classes\": num_classes,\n",
    "                   \"correct_label\": correct_label,\n",
    "                   \"learning_rate\": learning_rate,\n",
    "                   \"EPOCHS\": EPOCHS,\n",
    "                   \"BATCH_SIZE\": BATCH_SIZE,\n",
    "                   \"runs_dir\": runs_dir\n",
    "             }\n",
    "    \n",
    "    # place holder\n",
    "\n",
    "    \n",
    "    run(**params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./data/vgg/variables/variables\n",
      "WARNING:tensorflow:From <ipython-input-4-8ce0ae5e5acb>:8: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Model build successfully, start training.\n",
      "Epoch 1 ...\n",
      "Loss = 200.229\n",
      "\n",
      "Epoch 2 ...\n",
      "Loss = 4.830\n",
      "\n",
      "Epoch 3 ...\n",
      "Loss = 4.110\n",
      "\n",
      "Epoch 4 ...\n",
      "Loss = 3.954\n",
      "\n",
      "Epoch 5 ...\n",
      "Loss = 3.371\n",
      "\n",
      "Epoch 6 ...\n",
      "Loss = 3.107\n",
      "\n",
      "Epoch 7 ...\n",
      "Loss = 3.028\n",
      "\n",
      "Epoch 8 ...\n",
      "Loss = 3.003\n",
      "\n",
      "Epoch 9 ...\n",
      "Loss = 2.729\n",
      "\n",
      "Epoch 10 ...\n",
      "Loss = 2.973\n",
      "\n",
      "Epoch 11 ...\n",
      "Loss = 2.919\n",
      "\n",
      "Epoch 12 ...\n",
      "Loss = 2.633\n",
      "\n",
      "Epoch 13 ...\n",
      "Loss = 2.362\n",
      "\n",
      "Epoch 14 ...\n",
      "Loss = 2.409\n",
      "\n",
      "Epoch 15 ...\n",
      "Loss = 2.544\n",
      "\n",
      "Epoch 16 ...\n",
      "Loss = 2.437\n",
      "\n",
      "Epoch 17 ...\n",
      "Loss = 2.319\n",
      "\n",
      "Epoch 18 ...\n",
      "Loss = 2.111\n",
      "\n",
      "Epoch 19 ...\n",
      "Loss = 2.096\n",
      "\n",
      "Epoch 20 ...\n",
      "Loss = 1.952\n",
      "\n",
      "Epoch 21 ...\n",
      "Loss = 1.915\n",
      "\n",
      "Epoch 22 ...\n",
      "Loss = 1.961\n",
      "\n",
      "Epoch 23 ...\n",
      "Loss = 1.915\n",
      "\n",
      "Epoch 24 ...\n",
      "Loss = 1.929\n",
      "\n",
      "Epoch 25 ...\n",
      "Loss = 1.802\n",
      "\n",
      "Epoch 26 ...\n",
      "Loss = 1.642\n",
      "\n",
      "Epoch 27 ...\n",
      "Loss = 1.493\n",
      "\n",
      "Epoch 28 ...\n",
      "Loss = 1.448\n",
      "\n",
      "Epoch 29 ...\n",
      "Loss = 1.480\n",
      "\n",
      "Epoch 30 ...\n",
      "Loss = 1.394\n",
      "\n",
      "Epoch 31 ...\n",
      "Loss = 1.277\n",
      "\n",
      "Epoch 32 ...\n",
      "Loss = 1.198\n",
      "\n",
      "Epoch 33 ...\n",
      "Loss = 1.163\n",
      "\n",
      "Epoch 34 ...\n",
      "Loss = 1.160\n",
      "\n",
      "Epoch 35 ...\n",
      "Loss = 1.151\n",
      "\n",
      "Epoch 36 ...\n",
      "Loss = 1.120\n",
      "\n",
      "Epoch 37 ...\n",
      "Loss = 1.038\n",
      "\n",
      "Epoch 38 ...\n",
      "Loss = 1.046\n",
      "\n",
      "Epoch 39 ...\n",
      "Loss = 1.020\n",
      "\n",
      "Epoch 40 ...\n",
      "Loss = 0.964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
